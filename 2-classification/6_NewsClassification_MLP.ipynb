{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Lab 6\n",
    "\n",
    "## News Classification with Feed Forward Neural Networks (Multi-Layer Perceptrons)\n",
    "\n",
    "In this notebook we will use the cnn headline dataset that has 130000 news titles and their category between: Sports, Business, Sci-Tec and World.\n",
    "\n",
    "Take it slow and notice we will leverage the embeddings we learned before, and notice the last layer will need a softmax and as many cells as categories we have.\n",
    "\n",
    "You can run this lab both locally or in Colab.\n",
    "\n",
    "- To run in Colab just go to `https://colab.research.google.com`, sign-in and you upload this notebook. Colab has GPU access for free.\n",
    "- To run locally just run `jupyter notebook` and access the notebook in this lab. You would need to first install the requirements in `requirements.txt`\n",
    "\n",
    "Follow the instructions. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEqSAWGgNeRx",
    "outputId": "c0889c5e-6e23-4608-c603-1a0429b24843"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IY2pTPBPir1",
    "outputId": "09786002-0f1e-4c59-e11e-7f9b68c990a2"
   },
   "outputs": [],
   "source": [
    "!pip install textblob 'keras-nlp' 'keras-preprocessing' 'gensim==4.2.0' np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gZklVraP2vn",
    "outputId": "349c010b-5560-44d0-fb48-5efbf218b6bc"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n",
    "import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from textblob import TextBlob, Word\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import Constant\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "import pickle\n",
    "from tensorflow.nn import leaky_relu\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob\n",
    "\n",
    "TRACE = False\n",
    "embedding_dim = 300\n",
    "epochs=100\n",
    "batch_size = 250\n",
    "corpus_size=25000\n",
    "BATCH = True\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  tf.random.set_seed(42)\n",
    "  random.seed(42)\n",
    "  if TRACE:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def set_session_with_gpus_and_cores():\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  sess = tf.compat.v1.Session(config=config) \n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "set_seeds_and_trace()\n",
    "set_session_with_gpus_and_cores()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "textblob_tokenizer = lambda x: TextBlob(x).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0DZp9-YP8Fa",
    "outputId": "030ff14b-b462-4af1-d09d-e0e1a920e2dc"
   },
   "outputs": [],
   "source": [
    "%%writefile get_data.sh\n",
    "if [ ! -f news.csv ]; then\n",
    "  wget -O news.csv https://www.dropbox.com/s/352x7xzivf60zgc/news.csv?dl=0\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Arc-2X3AS2dI"
   },
   "outputs": [],
   "source": [
    "!bash get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIsjpoQMS5tT"
   },
   "outputs": [],
   "source": [
    "path = './news.csv'\n",
    "news_pre = pd.read_csv(path, header=0).sample(n=corpus_size).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e48igNipS-7m"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, should_join=True):\n",
    "    # Use the tokenizer to tokenize into words, lowercase them, remove punctuation, and finally use gensim.utils.simple_preprocess(text)\n",
    "    text = None\n",
    "    if should_join:\n",
    "      return ' '.join(gensim.utils.simple_preprocess(text))\n",
    "    else:\n",
    "      return gensim.utils.simple_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "AmuzxBe0S-45",
    "outputId": "c34d64e0-c975-4559-ad1c-93fe6edbb700"
   },
   "outputs": [],
   "source": [
    "news = news_pre.title.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI4j9GohS-1k"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = 'news.csv'\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield preprocess_text(line, should_join=False)\n",
    "\n",
    "\n",
    "word2vec_model = None\n",
    "# Get a word2vec model using gensim.models and passing the sentences using MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g02Wjl0NS-y2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = None  # Get the weights of the model (the embedding) and convert to tensor. Hint: Check word2vec_model.wv\n",
    "vocab_size = None  # get vocab size from index_to_key in word2vec_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS0pq9sbO7hy",
    "outputId": "5806a79e-fbf1-49ca-e813-8f01d80cdaca"
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "news_preprocessed = pd.DataFrame()\n",
    "news_preprocessed['label'] = news_pre.category.map({'Business': 0, 'Sports': 1, 'Sci/Tech': 2, 'World': 3})\n",
    "news_preprocessed['title'] = news\n",
    "news_preprocessed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Fsl1VwnVJoz"
   },
   "outputs": [],
   "source": [
    "def get_maximum_review_length(df):\n",
    "    maximum = 0\n",
    "    for ix, row in df.iterrows():\n",
    "        candidate = len(tokenizer(row.title))\n",
    "        if candidate > maximum:\n",
    "            maximum = candidate\n",
    "    return maximum\n",
    "\n",
    "\n",
    "maximum = get_maximum_review_length(news_preprocessed)   # Since 2 titles may have different number of words, we have to find the max length and fill with 0s if a title is shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cFi0e_sVJmh"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(news_preprocessed), maximum))   # Here we do what we said above\n",
    "# Iterate through the news df and for every word, if it exists in the word2vec model, put into X for that review and that word the index of the embedding (check index_to_key)\n",
    "# HINT: to iterate through a column of a pandas dataframe you do:\n",
    "\n",
    "# for index, value in df.iterrows():\n",
    "#      #do something\n",
    "\n",
    "# FILL\n",
    "y = news_preprocessed.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HspIJVUBVJkF"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = tf.constant(X_train)\n",
    "X_test = tf.constant(X_test)\n",
    "# Convert y_train and y_test from an array of values between 0-3 to a one hot matrix tensor\n",
    "y_train = None\n",
    "y_test = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzrIQ4G0VJhh"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add()  # Add an Embedding layer with weights being the rweights variable and trainable as False. The embedding dimension should be embedding_dim\n",
    "model.add()  # Add a couple of Dense Layers with RELU or leaky_relu activations. You may add Batch Norm if you want too\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(None, embedding_dim,)))  # Average out the words of the sentence. The expected out is (N, D) where N is number f samples in batch and D is embedding dimension\n",
    "model.add()  # Add final Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8T-hPDiIVJe9",
    "outputId": "f8fdd620-e9d7-4379-ce3b-9ada0f79d8de"
   },
   "outputs": [],
   "source": [
    "# Compile the model. Think what is the best loss to use\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCQiCKLSVJcg",
    "outputId": "17838bab-c6bc-4c62-ea4a-edf15cf63231"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.01)\n",
    "history = None # Fit the model, use the callback above to do EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "tDKdanUVa4GT",
    "outputId": "f5adbbe7-fd5b-4ff3-de3e-f0f12a2e1926"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# function for plotting loss\n",
    "def plot_metrics(train_metric, val_metric=None, metric_name=None, title=None, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    if val_metric is not None: plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plot loss history\n",
    "plot_metrics(history.history['loss'], history.history['val_loss'], \"Loss\", \"Loss\", ylim=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3N8INqJczF0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test with the following two sentences:\n",
    "# - 'supercomputer will put workers jobless soon'\n",
    "# - 'patriots goes winning super bowl'\n",
    "\n",
    "x_val = np.zeros((2, maximum))\n",
    "for index, row in enumerate(['supercomputer will put workers jobless soon', 'patriots goes winning super bowl']):\n",
    "    pass\n",
    "y_val = tf.one_hot([0,1], depth=4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPpbL+A74Cm32ZMBAp7PXg/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}