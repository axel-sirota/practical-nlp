{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Sentiment Analysis as Classification\n",
    "\n",
    "In this notebook we will use the IMDB reviews dataset and your task is to predict the sentiment of reviews\n",
    "\n",
    "You can run this lab both locally or in Colab.\n",
    "\n",
    "- To run in Colab just go to `https://colab.research.google.com`, sign-in and you upload this notebook. Colab has GPU access for free.\n",
    "- To run locally just run `jupyter notebook` and access the notebook in this lab. You would need to first install the requirements in `requirements.txt`\n",
    "\n",
    "Follow the instructions. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "# CRITICAL: Version constraints for compatibility\n# These versions are tested and required for this course\n!pip install 'numpy<2' \\\n             'gensim==4.2.0' \\\n             'tensorflow==2.15.0' \\\n             'tensorflow-text==2.15.0' \\\n             'keras-preprocessing' \\\n             textblob \\\n             np_utils",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import tensorflow as tf\nimport sys\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom textblob import TextBlob, Word\nfrom keras_preprocessing.sequence import pad_sequences\nfrom keras.initializers import Constant\nimport numpy as np\nimport random\nimport os\nimport pandas as pd\nimport gensim\nimport warnings\nimport nltk\nimport pickle\nfrom tensorflow.nn import leaky_relu\nfrom tensorflow.keras.datasets import imdb\n\nimport re\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom textblob import TextBlob\n\nTRACE = False\nembedding_dim = 100\nepochs=100\nbatch_size = 250\ncorpus_size=25000\nBATCH = True\n\ndef set_seeds_and_trace():\n  os.environ['PYTHONHASHSEED'] = '0'\n  np.random.seed(42)\n  tf.random.set_seed(42)\n  random.seed(42)\n  if TRACE:\n    tf.debugging.set_log_device_placement(True)\n\nset_seeds_and_trace()\nwarnings.filterwarnings('ignore')\nnltk.download('punkt')\ntextblob_tokenizer = lambda x: TextBlob(x).words"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-venv",
   "language": "python",
   "name": "global-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}