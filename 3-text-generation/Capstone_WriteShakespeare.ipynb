{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Capstone: Write Like Shakespeare\n",
    "\n",
    "In this notebook we will use a file of shakespearean sonnets, and your task is to predict create a text generation model that writes like shakespeare\n",
    "\n",
    "You can run this lab both locally or in Colab.\n",
    "\n",
    "- To run in Colab just go to `https://colab.research.google.com`, sign-in and you upload this notebook. Colab has GPU access for free.\n",
    "- To run locally just run `jupyter notebook` and access the notebook in this lab. You would need to first install the requirements in `requirements.txt`\n",
    "\n",
    "Follow the instructions. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "# CRITICAL: Version constraints for compatibility\n# These versions are tested and required for this course\n!pip install 'numpy<2' \\\n             'gensim==4.2.0' \\\n             'tensorflow==2.15.0' \\\n             'tensorflow-text==2.15.0' \\\n             'keras-preprocessing' \\\n             textblob \\\n             np_utils \\\n             swifter",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "import tensorflow as tf\nimport sys\nimport keras.backend as K\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout, LSTM, Bidirectional, Input, RepeatVector, Concatenate\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom textblob import TextBlob, Word\nfrom keras_preprocessing.sequence import pad_sequences\nfrom keras.initializers import Constant\nimport numpy as np\nimport random\nimport os\nimport pandas as pd\nimport gensim\nimport warnings\nimport nltk\nimport pickle\nimport re\nimport swifter\n\nfrom sklearn.model_selection import train_test_split\nfrom textblob import TextBlob\n\nTRACE = False\nembedding_dim = 300\nepochs=2\nbatch_size = 64\nmax_tokens = 200\nBATCH = True\n\ndef set_seeds_and_trace():\n  os.environ['PYTHONHASHSEED'] = '0'\n  np.random.seed(42)\n  tf.random.set_seed(42)\n  random.seed(42)\n  if TRACE:\n    tf.debugging.set_log_device_placement(True)\n\nset_seeds_and_trace()\nwarnings.filterwarnings('ignore')\nnltk.download('punkt')\ntextblob_tokenizer = lambda x: TextBlob(x).words",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "import os\nimport random\nimport warnings\n\nimport keras.backend as K\nimport nltk\nimport numpy as np\nimport tensorflow as tf\n\nTRACE = False\nepochs=50\nbatch_size = 256\nbuffer_size = 1000\nembedding_dim = 150\nrnn_units = 1024\nseq_length = 150\n\ndef set_seeds_and_trace():\n  os.environ['PYTHONHASHSEED'] = '0'\n  np.random.seed(42)\n  tf.random.set_seed(42)\n  random.seed(42)\n  if TRACE:\n    tf.debugging.set_log_device_placement(True)\n\nset_seeds_and_trace()\nwarnings.filterwarnings('ignore')\nnltk.download('punkt')\ntextblob_tokenizer = lambda x: TextBlob(x).words",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}